---
author:
    - name: T. Venturini
      orcid: 0000-0003-0004-5308
      affiliations:
      - ref: cis-cnrs
      - ref: ugen

affiliations:
- id: cis-cnrs
  name: Centre national de la recherche scientifique
  department: Centre for Internet and Society
  city: Paris
  country: France
- id: ugen
  name: University of Geneva
  city: Geneva
  country: Switzerland
---

# Citizen Science Indicators {#citizen-science-indicators .unnumbered}

History (please fill out in reverse chronological order, latest revision on top):

|         |               |             |              |
|---------|---------------|-------------|--------------|
| Version | Revision date | Revision    | Author       |
| 1.0     | 2023-03-23    | First draft | T. Venturini |

## []{#_Ref126739570}Description

While there are many competing definitions of citizen science (also called participatory, community, civic, crowd-sourced volunteer science), the notion is generally used to refer to scientific knowledge production with the active participation of the public (i.e., lay people or non-experts, who are not professionally affiliated with academic or industrial research initiatives). Citizen science plays a key role in the movement towards Open Science by opening up the means of knowledge production to the participation of societal actors, across the entire research cycle. In citizen science projects, the public can contribute to scientific efforts in different ways, by taking part in

-   the definition of the objectives or the research \[1. design\];
-   the development of hypotheses, research questions and methods \[2. development\];
-   the collection of records or knowledge \[3. Data collection\];
-   the cleaning and preparation of the datasets \[4. processing\];
-   the analysis of the data \[5. analysis\];
-   the interpretation of the results \[6. interpretation\];
-   the dissemination of the findings/conclusions \[7. dissemination\];
-   the conservation and sharing of the resources generated by the project \[8. ownership\]
-   the recognition as authors/protagonists of the research \[9. credit\]

This document describes a series of metrics to quantify (but also qualify) each of these nine different forms of citizen participation in science, as well as a tenth indicator accounting for the capacity of a citizen sciences project to span across multiple forms of participation \[10. span\].

## Existing datasources

Data on citizen science projects can be derived from five different sources:

###### Scientific project portals

While they tend to have a distinctive approach many citizen science projects still consider themselves as science projects, and are generally funded as such. This means that these projects will be listed in national and international directories, particularly those kept by research funders. Information extracted from these portals can therefore be used to know more about the subjects, the institutions and the finance of citizen science and, most importantly, to compare these projects to the rest of the scientific project financed in the same years or addressing the same topics.

###### Individual project websites

Because they need to recruit citizens willing to contribute to their research effort, many citizen science projects have developed websites that describe the objectives, activities and results. These websites can be harvested to collect information about the projects and calculate the metrics described below. Examples include:

-   Globe at Night - <https://www.globeatnight.org/>
-   Project FeederWatch - <https://feederwatch.org/>
-   eBird - <https://ebird.org/home>
-   Foldit - <https://fold.it/>
-   EyeWire - <https://eyewire.org/>
-   MilkyWay\@Home - <https://milkyway.cs.rpi.edu/milkyway/>
-   Phylo - <http://phylo.cs.mcgill.ca/>
-   SETI\@home - <https://setiathome.berkeley.edu/>
-   BOINC - <https://boinc.berkeley.edu/>
-   CoCoRaHS - <https://www.cocorahs.org/>

###### Citizen science web portals

The problem with collecting information from individual websites is that their content and architecture may vary significantly from one another and thus require considerable efforts for manual collection and standardisation of data. An increasing number of citizen science projects, however, tend to rely on specialized portals that facilitate some of their activities (e.g., the recruitment of volunteers; their training; the tracking of their contributions; the support of the interaction between volunteers and with the project organisers; etc.). Examples of Citizen science web portals includes

-   CitizenScience.gov - <https://www.citizenscience.gov/>
-   Zooniverse - <https://www.zooniverse.org/>
-   EU-Citizen.Science - <https://eu-citizen.science/>
-   SciStarter - <https://scistarter.org/>
-   BOINC - <https://boinc.berkeley.edu/>

###### Bibliographic database

As for all research projects, the primary output of citizen sciences projects consists of scientific publications. These publications are stored in bibliographic databases and are often available as open access publication (because of the obvious affinity between this type of publication and the approach of civic science). Most of these publications will mention the fact that their results are based on a participatory initiative, cite one of the main citizen science portals or be signed with a collective name. All these signs facilitate the identification of publications from citizen science initiatives, allowing analyzing their publication results and to compare them with the rest of the scientific literature.

###### Data portals

Besides their publication, citizen science projects also tend to openly publish their dataset in an effort to give back to the public the information collected through its cooperation. Some of these datasets will be released through the individual websites of each project, but some may be published through general data portals, making it possible to collect information that is standardized and comparable with non-participatory projects.

## Metrics

Many citizen science projects tend to concentrate on the central steps of the research process (the collection, processing and analysis of data) as these steps can be externalized (or crowd-sourced) without losing control of the research. These are also the steps on which more information is available since, by dealing with data, these activities are also the easiest to datafy. It is however crucial to gauge the participatory nature of all the stages of a research because real openness can only be achieved if all or most of these stages are truly receptive to public input.

### Citizen science design

This metric is meant to assess to what extent citizens have been involved in the decisions surrounding the research project: Does the project address concerns that have been surfaced by the community that participate to the project? Have the research questions been defined in collaboration with the public? Is the project led by academic publication/career objectives or is also guided by civic preoccupations?

This metric is one of the subtlest for this indicator and can only be assessed by qualitative analysis. To assess citizen science design, researchers can investigate the history of the projects and discuss with their protagonists, or they can closely read the project documentations to detect if people and concerns from outside the academia are considered and highlighted.

### Citizen science development

This step is probably the one that is the least often open to citizen participation. Some scientists would indeed argue that this step should be kept under the control of the expert to assure that the development of the research protocol and methodology remain strictly adherent to scientific best practices, thus guaranteeing the value of the data as well as their comparability. Proponents of a more extreme participatory approach, however, will argue (not without reason) that this is the key step of any research project and that if this stage is not open to the public, than citizens cannot truly be the protagonists of the research (and will instead be relegated to the role of useful, but powerless helpers).

As the previous one (and maybe even more than it), this metric can only be assessed through careful qualitative inspection, considering the description of the research protocol and the way in which it has been put together.

### Citizen science data collection

This is one of the research steps that has been more traditionally crowdsourced to lay people. Since the Renaissance amateur naturalists have participated in the effort of logging and cataloging different species of plants and animals together with their counterparts in academia. This tradition continues today as biodiversity loss demands to observe and count the movement of different species of insects, birds and amphibians.

Because this step concerns the harvesting of data it is easy to imagine metrics related to the quantity and quality of information collected by citizens, for example:

-   Percentage of data collected by citizens of the total amount of data harvested by the project.
-   Number of sites or phenomena that are observed exclusively or predominantly by citizens.
-   Importance of the crowdsourced data versus other data sources.

### Citizen science processing

If data collection is the most classic of crowdsourced scientific activities, the cleaning and (pre)processing of data is the step that is most often crowd-sourced in contemporary citizen projects. A classic hurdle of current research is an overabundance of poor quality. In the last decades, sensors and other digital technologies have multiplied the number of records collected and stored by scientific projects, but have also increased the noise associated with them. Duplicates, errors, impossible outliers need to be detected manually and carefully removed before moving on with the analysis.

The role played by citizens in this work of data processing can be measure through

-   Absolute or relative number of errors corrected by citizens.
-   Number of hours (or days) invested in manual data cleaning.
-   Increase in the quality of data (how such quality is measured depends of course on the specific project)

### Citizen science analysis

This step is very close to the previous one and in many cases significantly overlaps with it. The distinction is made only to separate the relative low-level work of detecting and removing obvious errors, from the slightly or significantly more high-level effort of detecting meaningful patterns and trends in the datasets. Despite the stunning progress of artificial intelligence and other computational techniques, human being remains crucial in the process of pattern recognition and unreplaceable in the constitution of qualified datasets that can be used for machine learning training.

Possible metrics includes:

-   Absolute or relative size of the data analyses by citizens.
-   Number of hours (or days) invested in the analysis.
-   Absolute or relative numbers of pattern discovered by citizens (as compared to expert or automatic detection).

### Citizen science interpretation

While the two previous steps (processing and analysis) can be simplified (and sometime gamified) to the point of being accessible to anyone – and for this reason represent the standard activities for crowdsourced science – this step is less often entrusted to citizens as it requires a greater training and knowledge of the subject. However, the more the citizens are associated to interpretation (which is the step where the greatest scientific value is produce) and the more they have agency in it, the more the research can be said to be truly open and participatory.

To assess the role of lay experts in the interpretation of data and generation of findings, one can assess

-   Complexity and significance of crowdsourced research tasks.
-   Possibility for citizen participants to complete findings/results autonomously (as opposed to intervening only in low level activities, but not being able to achieve the results).
-   Participation of citizens in the writing up of the research conclusions.

### Citizen science dissemination

Many observers and organizers of citizen science projects have argued that, even when it fails to produce new data or findings, one of the main advantages of this approach is that it sensitizes the public to the work of research and helps build science literacy. Because it involves people outside academia (sometimes in large numbers) citizen science has built-in dissemination effects.

The significance of these effects can be measure by

-   Number of regular VS occasional contributors.
-   Increase of the number or quality of contribution over time.
-   Diversification of the projects that citizens contribute to (when using the same account to participate in different projects within the same portal).

### Citizen science ownership

Because in participatory science projects, citizens provide an important part of the work that allows the development of research, it is important its results are also shared with them – be them datasets, scientific findings, and possibly their intellectual or commercial offshoots.

To assess how ownership is shared among all the actors who participated to a citizen science initiative, researchers can look for:

-   Legal mechanisms assuring the public ownership of the data or results of the project (e.g., open licenses or collective patents).
-   Organizational mechanisms assuring that members/representatives of the public are associated with all decisions related to the research and all the benefits generated by it.
-   Political, economic or civil society initiatives deriving from the project and the way in which they are carried out by the same people VS a subset of the people who contributed to the research.

### Citizen science credit

Crediting the people who have contributed to the production of science can be as important as granting them the actual ownership of the data or of the results of the research. Sometimes, crediting (in the form of signing or otherwise authoring scientific publication) is actually more important than ownership as the primary source of recognition of scientific work.

Crediting can be assessed by:

-   Number of publications (in scientific journals, conference proceedings or books) that mention the use of a citizen science approach.
-   Number of publications that mention the name of all the individuals or of the citizen organizations that have contributed to the research.
-   Number of publications signed by authors outside academia and industrial R&D or signed under a collective name.

### Citizen science span

The metrics described above refer to specific stages of the research process, but (as explained in section I) the opening of multiple steps is even more important.

-   The most straightforward way of measuring this is by the simple count of the number of steps in which citizens have been given a chance to be active.
-   A less binary option is to define a scale of “citizen agency/participation” for each step and then compute the average value across the whole research protocol.

## Known correlatesNotesReferences

Gabrys, J., Pritchard, H., & Barratt, B. (2016). Just good enough data: Figuring data citizenships through air pollution sensing and data stories. *Big Data & Society*, *3*(2), 205395171667967. https://doi.org/10.1177/2053951716679677

Lämmerhirt, D., Gray, J., Venturini, T., & Meunier, A. (2019). Advancing Sustainability Together? Citizen-Generated Data and the Sustainable Development Goals. *SSRN Electronic Journal*. https://doi.org/10.2139/ssrn.3320467

﻿Shirk, J. L., Ballard, H. L., Wilderman, C. C., Phillips, T., Wiggins, A., Jordan, R., … Bonney, R. (2012). Public participation in scientific research: A framework for deliberate design. *Ecology and Society*, 17(2). https://doi.org/10.5751/ES-04705-170229

Strasser, B. J., Baudry, J., Mahr, D., Sanchez, G., & Tancoigne, E. (2017). “Citizen Science”? Rethinking Science and Public Participation. *Science & Technology Studies,* *Forthcomin*.
